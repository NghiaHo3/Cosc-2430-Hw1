# Load data
data("USArrests")
my_data <- USArrests
my_data <- na.omit(my_data)
# Scale variables
my_data <- scale(my_data)
get_clust_tendency(my_data, n = 50, gradient = list(low = "steelblue",  high = "white"))
install.packages("cluster")
install.packages("factoextra")
install.packages("factoextra")
install.packages("factoextra")
# Load data
data("USArrests")
my_data <- USArrests
# Remove any missing value (i.e, NA values for not available)
# This does not seem usefult here because the dataset is already complete. Furthermore,
# it may not be possible for us to eliminate incomplete cases, as we may end up with
# an empty dataset.
# MUST INVESTIGATE HOW CLUSTERING HANDLES MISSING VARIABLES
my_data <- na.omit(my_data)
# Scale variables
my_data <- scale(my_data)
library("cluster")
library("factoextra")
get_clust_tendency(my_data, n = 50, gradient = list(low = "steelblue",  high = "white"))
get_clust_tendency(my_data, n = 49, gradient = list(low = "steelblue",  high = "white"))
gap_stat <- clusGap(my_data, FUN = kmeans, K.max = 10, B = 500)
fviz_gap_stat(gap_stat)
# Or use (equivalent)
fviz_nbclust(my_data, kmeans, method = "gap_stat")
km.res <- kmeans(my_data, 4, nstart = 25)
fviz_cluster(km.res, data = my_data, frame.type = "convex") + theme_minimal()
sil <- silhouette(km.res$cluster, dist(my_data))
head(sil)
head(sil[, 1:3], 10)
plot(sil, main ="Silhouette plot - K-means")
fviz_silhouette(sil)
si.sum <- summary(sil)
si.sum$clus.avg.widths
si.sum
fviz_silhouette(sil)  #alternative plot with factoextra
fviz_silhouette(km.res)
sil.w <- sil$silinfo$widths[, 1:3]
neg_sil_index <- which(sil[, 'sil_width'] < 0)
sil[neg_sil_index, , drop = FALSE]
View(my_data)
sil <- km.res$silinfo$widths[, 1:3]
neg_sil_index <- which(sil[, 'sil_width'] < 0)
sil[neg_sil_index, , drop = FALSE]
# Silhouette information
silinfo <- sil$silinfo
names(silinfo)
silinfo <- km.res$silinfo
?silhouette
pam.res <- pam(my_data, 4)
silinfo <- pam.res$silinfo  # field not available for kmeans
names(silinfo)
sil <- pam.res$silinfo$widths[, 1:3]
neg_sil_index <- which(sil[, 'sil_width'] < 0)
sil[neg_sil_index, , drop = FALSE]
fviz_silhouette(sil)  #alternative plot with factoextra
sil <- silhouette(pam.res$cluster, dist(my_data))
head(sil[, 1:3], 10)
plot(sil, main ="Silhouette plot - K-means")
plot(sil, main ="Silhouette plot - PAM")
fviz_silhouette(sil)  #alternative plot with factoextra
sil.w <- pam.res$silinfo$widths[, 1:3]
neg_sil_index <- which(sil[, 'sil_width'] < 0)
sil[neg_sil_index, , drop = FALSE]
silinfo <- pam.res$silinfo  # field not available for kmeans
sil.w <- pam.res$silinfo$widths[, 1:3]
neg_sil_index <- which(sil[, 'sil_width'] < 0)
sil[neg_sil_index, , drop = FALSE]
neg_sil_index <- which(sil.w[, 'sil_width'] < 0)
sil.w[neg_sil_index, , drop = FALSE]
View(sil.w)
d <- dist(my_data, method = "euclidean")
km_stats <- cluster.stats(d,  km.res$cluster)
library(NbClust)
install.packages("NbClust")
library(NbClust)
?NbClust
install.packages("fpc")
km_stats <- cluster.stats(d,  km.res$cluster)
library(fpc)
km_stats <- cluster.stats(d,  km.res$cluster)
km_stats$dunn
data <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
head(data)
summary(data)
training <- data[1:270,]
testing <- data[270:400,]
# PL4
GRElogit <- glm(admit ~ gre, data = training, family = "binomial")
summary(GRElogit)
mylogit <- glm(admit ~ gre + gpa + rank, data = training, family = "binomial")
mylogit
sapply(data,class)
data$rank <- factor(data$rank)
sapply(data,class)
# PL3
training <- data[1:270,]
testing <- data[270:400,]
# PL4
GRElogit <- glm(admit ~ gre, data = training, family = "binomial")
summary(GRElogit)
mylogit <- glm(admit ~ gre + gpa + rank, data = training, family = "binomial")
mylogit
data("mtcars")
dat <- subset(mtcars, select=c(mpg, am, vs))
logr_vm <- glm(am ~ mpg, data=dat, family=binomial)
logr_vm
rank_logit <- glm(admit ~ rank, data = training, family = "binomial")
summary(rank_logit)
gpa_logit <- glm(admit ~ gpa, data = training, family = "binomial")
summary(gpa_logit)
mylogit <- glm(admit ~ gre + gpa + rank, data = training, family = "binomial")
summary(mylogit)
summary(rank_logit)
exp(coef(mylogit))
View(mtcars)
?mtcars
cars_logit <- glm(am ~ mpg + hp, data=mtcars, family=binomial)
exp(cbind(OR = coef(cars_logit), confint.default(cars_logit)))
cars_logit <- glm(am ~ mpg + hp + cyl, data=mtcars, family=binomial)
exp(cbind(OR = coef(cars_logit), confint.default(cars_logit)))
cars_logit <- glm(am ~ mpg + hp + carb, data=mtcars, family=binomial)
exp(cbind(OR = coef(cars_logit), confint.default(cars_logit)))
cars_logit <- glm(am ~ hp + carb, data=mtcars, family=binomial)
exp(cbind(OR = coef(cars_logit), confint.default(cars_logit)))
cars_logit <- glm(am ~ mpg + carb, data=mtcars, family=binomial)
exp(cbind(OR = coef(cars_logit), confint.default(cars_logit)))
cars_logit <- glm(am ~ mpg + cyl, data=mtcars, family=binomial)
exp(cbind(OR = coef(cars_logit), confint.default(cars_logit)))
summary(cars_logit)
cars_logit <- glm(am ~ mpg + hp + cyl, data=mtcars, family=binomial)
summary(cars_logit)
exp(cbind(OR = coef(cars_logit), confint.default(cars_logit)))
exp(cbind(OR = coef(mylogit), confint.default(mylogit)))
mylogit
increment <- 10
lmod <- list(mod1 = mylogit)
SE <- sapply(lmod, function(x) coef(summary(x))[,2])
OR = increment*coef(mylogit)
exp(cbind(OR, lowCI = OR - 1.96*increment*SE, highCI = OR + 1.96*increment*SE))
increment <- 20
lmod <- list(mod1 = mylogit)
SE <- sapply(lmod, function(x) coef(summary(x))[,2])
OR = increment*coef(mylogit)
exp(cbind(OR, lowCI = OR - 1.96*increment*SE, highCI = OR + 1.96*increment*SE))
library(lmtest)
lrtest(logr_vm)
install.packages("lmtest")
library(lmtest)
lrtest(logr_vm)
?lrtest
lrtest(logr_vm, cars_logit)
gparank_logit <- glm(admit ~ gpa + rank, data = training, family = "binomial")
lrtest(gparank_logit)
lrtest(gparank_logit, GRElogit)
gpagre_logit <- glm(admit ~ gpa + gre, data = training, family = "binomial")
lrtest(gpagre_logit)
lrtest(rank_logit, gpagre_logit)
data <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
head(data)
summary(data)
# PL2
sapply(data,class)
data$rank <- factor(data$rank)
sapply(data,class)
# PL3
training <- data[1:270,]
testing <- data[270:400,]
mylogit <- glm(admit ~ gre + gpa + rank, data = training, family = "binomial")
P <- predict(mylogit, newdata = testing, type = "response")
training <- data[1:270,]
testing <- data[271:400,]
P <- predict(mylogit, newdata = testing, type = "response")
View(testing)
max(P)
find(max(P))
find(P,max(P))
?find
find(max(P),P)
match(max(P),P)
P
predictions <- as.numeric(P > 0.5)
tail(P)
tail(predictions)
sum(predictions)
sum(testing$admit)
library(ResourceSelection)
hoslem.test(prediction, testing$admit)
install.packages("ResourceSelection")
library(ResourceSelection)
hoslem.test(prediction, testing$admit)
hoslem.test(predictions, testing$admit)
perf = function(cut, mod, y)
{
yhat = (mod$fit>cut)
w = which(y==1)
sensitivity = mean( yhat[w] == 1 )
specificity = mean( yhat[-w] == 0 )
c.rate = mean( y==yhat )
d = cbind(sensitivity,specificity)-c(1,1)
d = sqrt( d[1]^2 + d[2]^2 )
out = t(as.matrix(c(sensitivity, specificity, c.rate,d)))
colnames(out) = c("sensitivity", "specificity", "c.rate", "distance")
return(out)
}
s = seq(.01,.99,length=1000)
OUT = matrix(0,1000,4)
for(i in 1:1000) OUT[i,]=perf(s[i],mylogit,testing$predict)
plot(s,OUT[,1],xlab="Cutoff",ylab="Value",cex.lab=1.5,cex.axis=1.5,ylim=c(0,1),type="l",lwd=2,axes=FALSE,col=2)
axis(1,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
axis(2,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
lines(s,OUT[,2],col="darkgreen",lwd=2)
lines(s,OUT[,3],col=4,lwd=2)
lines(s,OUT[,4],col="darkred",lwd=2)
box()
legend(.8,.85,col=c(2,"darkgreen",4,"darkred"),lwd=c(2,2,2,2),cex = 0.7,c("Sensitivity","Specificity","Accuracy","Distance"))
s = seq(.01,.99,length=1000)
OUT = matrix(0,1000,4)
for(i in 1:1000) OUT[i,]=perf(s[i],mylogit,predictions)
plot(s,OUT[,1],xlab="Cutoff",ylab="Value",cex.lab=1.5,cex.axis=1.5,ylim=c(0,1),type="l",lwd=2,axes=FALSE,col=2)
axis(1,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
axis(2,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)
lines(s,OUT[,2],col="darkgreen",lwd=2)
lines(s,OUT[,3],col=4,lwd=2)
lines(s,OUT[,4],col="darkred",lwd=2)
box()
legend(.8,.85,col=c(2,"darkgreen",4,"darkred"),lwd=c(2,2,2,2),cex = 0.7,c("Sensitivity","Specificity","Accuracy","Distance"))
predictions <- as.numeric(P > 0.3)
hoslem.test(predictions, testing$admit)
predictions <- as.numeric(P > 0.35)
hoslem.test(predictions, testing$admit)
sum(predictions)
predictions <- as.numeric(P > 0.34)
hoslem.test(predictions, testing$admit)
predictions <- as.numeric(P > 0.36)
hoslem.test(predictions, testing$admit)
sum(predictions)
predictions <- as.numeric(P > 0.37)
hoslem.test(predictions, testing$admit)
predictions <- as.numeric(P > 0.38)
hoslem.test(predictions, testing$admit)
sum(predictions)
predictions <- as.numeric(P > 0.39)
hoslem.test(predictions, testing$admit)
predictions <- as.numeric(P > 0.4)
hoslem.test(predictions, testing$admit)
predictions <- as.numeric(P > 0.41)
hoslem.test(predictions, testing$admit)
sum(predictions)
predictions <- as.numeric(P > 0.40)
hoslem.test(predictions, testing$admit)
sum(predictions)
library(caret)
confusionMatrix(prediction, testing$admit, positive = "1")
install.packages("caret")
library(caret)
predictions <- as.numeric(P > 0.5)
confusionMatrix(predictions, testing$admit, positive = "1")
install.packages("e1071")
library(caret)
predictions <- as.numeric(P > 0.5)
confusionMatrix(predictions, testing$admit, positive = "1")
data <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
head(data)
summary(data)
# PL2
sapply(data,class)
data$rank <- factor(data$rank)
sapply(data,class)
# PL3
training <- data[1:270,]
testing <- data[271:400,]
# PL4
data("mtcars")
dat <- subset(mtcars, select=c(mpg, am, vs))
logr_vm <- glm(am ~ mpg, data=dat, family=binomial)
logr_vm
# PL5
rank_logit <- glm(admit ~ rank, data = training, family = "binomial")
summary(rank_logit)
gpa_logit <- glm(admit ~ gpa, data = training, family = "binomial")
summary(gpa_logit)
# PL6
summary(rank_logit)
mylogit <- glm(admit ~ gre + gpa + rank, data = training, family = "binomial")
summary(mylogit)
# PL7
exp(coef(mylogit))
# PL9
cars_logit <- glm(am ~ mpg + hp + cyl, data=mtcars, family=binomial)
exp(cbind(OR = coef(cars_logit), confint.default(cars_logit)))
exp(cbind(OR = coef(mylogit), confint.default(mylogit)))
# PL11
increment <- 20
lmod <- list(mod1 = mylogit)
SE <- sapply(lmod, function(x) coef(summary(x))[,2])
OR = increment*coef(mylogit)
exp(cbind(OR, lowCI = OR - 1.96*increment*SE, highCI = OR + 1.96*increment*SE))
# PL12
library(lmtest)
lrtest(logr_vm)
lrtest(logr_vm, cars_logit)
# PL13
gpagre_logit <- glm(admit ~ gpa + gre, data = training, family = "binomial")
lrtest(gpagre_logit)
lrtest(rank_logit, gpagre_logit)
# PL14
P <- predict(mylogit, newdata = testing, type = "response")
match(max(P))
match(training,max(P))
match(P,max(P))
testing[24,]
testing[match(P,max(P))]
testing[match(P,max(P)),]
find(P,max(P))
index(P,max(P))
match(P==max(P))
testing[P==max(P),]
predictions <- as.numeric(P > 0.5)
sum(predictions)
# PL16
library(ResourceSelection)
hoslem.test(predictions, testing$admit)
# PL17
predictions <- as.numeric(P > 0.38)
hoslem.test(predictions, testing$admit)
# PL18-19-20
library(caret)
predictions <- as.numeric(P > 0.5)
confusionMatrix(predictions, testing$admit, positive = "1")
data <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
data <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
View(data)
?runif
runif(20, min=0, max=100)
runif(20, min=0, max=100)
runif(20, min=0, max=100)
?for
)
for (i in 1:10)
A[i] = runif(20, min=0, max=100);
?array
A = array(20)
for (i in 1:10)
A[i] = runif(20, min=0, max=100)
?matrix
A = matrix(20,20)
for (i in 1:10)
A[i,] = runif(20, min=0, max=100)
A = matrix(20,20)
for (i in 1:20)
for (j in 1:20)
A[i,j] = runif(1, min=0, max=100)
View(A)
A = matrix(20,20)
for (i in 1:20)
for (j in 1:20)
A[i,j] = runif(1, min=0, max=100)
A = matrix(20,20)
A = matrix(NA,20,20)
View(A)
for (i in 1:20)
for (j in 1:20)
A[i,j] = runif(1, min=0, max=100)
View(A)
write.table(A, "7.txt", sep=" ")
setwd("~/Desktop/UHclasses/2430/HW1/test cases scored")
write.table(A, "7.txt", sep=" ")
write.csv(A, "7.csv")
size = 3
A = matrix(NA,size, size)
for (i in 1:size)
for (j in 1:size)
A[i,j] = runif(round(1, min=0, max=10))
write.csv(A, "1.csv")
?floor
size = 3
A = matrix(NA,size, size)
for (i in 1:size)
for (j in 1:size)
A[i,j] = round(runif(1, min=0, max=10))
write.csv(A, "1.csv")
size = 5
A = matrix(NA,size, size)
for (i in 1:size)
for (j in 1:size)
A[i,j] = round(runif(1, min=0, max=10),2)
write.csv(A, "2.csv")
size = 5
A = matrix(NA,size, size)
for (i in 1:size)
for (j in 1:size)
A[i,j] = round(runif(1, min=-10, max=10),2)
write.csv(A, "3.csv")
size = 15
A = matrix(NA,size, size)
for (i in 1:size)
for (j in 1:size)
A[i,j] = round(runif(1, min=-10, max=10),3)
write.csv(A, "5.csv")
size = 10
A = matrix(NA,size, size)
for (i in 1:size)
for (j in 1:size)
A[i,j] = round(runif(1, min=-1000000, max=1000000))
write.csv(A, "6.csv")
